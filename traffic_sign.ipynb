{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/AndriiGoz/traffic_signs_classification/blob/master/traffic_signs_classification_lenet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"6rfQGTBIfIKE"},"source":["# Classification of Traffic Signs with LeNet-5 CNN\n","The purpose of this project is to train an implementation of the LeNet-5 Convolutional Neural Network for the classification of traffic signs. The model will be used in an application, where the user can upload a photo of a traffic sign and get the prediction of its class.\n"]},{"cell_type":"markdown","metadata":{"id":"ocnVL1zOdewc"},"source":["### 1. Mount Google Drive\n","The dataset was taken from *The German Traffic Sign Recognition Benchmark (GTSRB): https://benchmark.ini.rub.de/gtsrb_dataset.html.* It consists of about 40.000 real colorful photos of german traffic signs. The images have a .ppm extension and their size varies from 15x15 to 250x250 pixels. We save the dataset on Google Drive and access it using *drive.mount* command."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23591,"status":"ok","timestamp":1667184782168,"user":{"displayName":"John C","userId":"05446635347949987899"},"user_tz":-330},"id":"NEKbF7K7zaM4","outputId":"62c2d134-44f0-4425-8456-2b2be137d673"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"9IuVSwESfc5F"},"source":["### 2. Import libraries\n","Here we just import libraries we need in our Project: \n","- some standard ones as NumPy, OS, and Matplotlib;\n","- cv2, a powerful library developed for solving computer vision tasks (https://opencv.org/);\n","- [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for splitting the dataset into train and test subsets;\n","- some components from [tf.keras.models](https://www.tensorflow.org/api_docs/python/tf/keras/models)...;\n","- and from [tf.keras.layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers) for building the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x8PeqxEQ1YnK"},"outputs":[],"source":["import numpy as np\n","import random\n","import os\n","import cv2 as cv\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential, load_model\n","from keras.layers import Conv2D, Dense, Flatten, Rescaling, AveragePooling2D, Dropout"]},{"cell_type":"markdown","metadata":{"id":"Tn0MuuXBfgvr"},"source":["### 3. Read and pre-process image files\n","We start with reading images from the dataset. The images are distributed over 43 folders representing 43 classes. We loop through folders and through images, open them, resize to 32x32 pixels, convert from RGB to gray, and save them as np.arrays."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XH5JeW5h8Laz"},"outputs":[],"source":["images = []\n","labels = []\n","classes = 43\n","\n","current_path = '/content/gdrive/My Drive/GTSRB/Final_Training/Images/'\n","#current_path = '/My Drive/GTSRB/Final_Training/Images/'\n","\n","for i in range(classes):\n","    path = os.path.join(current_path, str(str(i).zfill(5)))\n","    img_folder = os.listdir(path)\n","    for j in img_folder:\n","        try:\n","            image = cv.imread(str(path+'/'+j))\n","            image = cv.resize(image, (32, 32))\n","            image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n","            image = np.array(image)\n","            images.append(image)\n","            label = np.zeros(classes)\n","            label[i] = 1.0\n","            labels.append(label)\n","        except:\n","            pass"]},{"cell_type":"markdown","metadata":{"id":"5ymeuijP64Gl"},"source":["We divide images by 255 to get pixel values between 0.0 and 1.0. Finally, we have got a total amount of 39.209 images assigned to 43 classes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1667107809179,"user":{"displayName":"John C","userId":"05446635347949987899"},"user_tz":-330},"id":"Iz3irQaBhxG7","outputId":"ae1c6cf2-7e7d-4cb4-d31a-eee231a3472f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Images shape: (0,)\n","Labels shape: (0,)\n"]}],"source":["images = np.array(images)\n","images = images/255\n","labels = np.array(labels)\n","print('Images shape:', images.shape)\n","print('Labels shape:', labels.shape)"]},{"cell_type":"markdown","metadata":{"id":"rCNorpIr5MA0"},"source":["### 4. Split Dataset into train and test subsets\n","The dataset has to be split now into train and test subsets. For the test subset, we take out a standard 20% of the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"elapsed":750,"status":"error","timestamp":1667107813365,"user":{"displayName":"John C","userId":"05446635347949987899"},"user_tz":-330},"id":"dgv5c_2neImU","outputId":"f119723a-bd61-4bac-f196-74a45589c4f6"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-02e6ae425cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_train shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[0;32m-> 2421\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m     )\n\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m             \u001b[0;34m\"aforementioned parameters.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m         )\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."]}],"source":["X = images.astype(np.float32)\n","y = labels.astype(np.float32)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n","\n","print('X_train shape:', X_train.shape)\n","print('y_train shape:', y_train.shape)\n","print('X_test shape:', X_test.shape)\n","print('y_test shape:', y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"SlDxmG7oeNzF"},"source":["\n","Let's take a look at some samples from our dataset. We pick up 25 random images and plot them together with their labels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VzLRoseR1IDI"},"outputs":[],"source":["plt.figure(figsize=(12, 12))\n","start_index = 0\n","for i in range(25):\n","    plt.subplot(5, 5, i+1)\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    \n","    label = np.argmax(y_train[start_index+i])\n","    \n","    plt.xlabel('i={}, label={}'.format(start_index+i, label))\n","    plt.imshow(X_train[start_index+i], cmap='gray')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"6ztqnu3Y0fXj"},"source":["### 5. Build the model\n","For our classification task, we will use an implementation of LeNet-5 Convolutional Neural Network. LeNet-5 was designed by Yann LeCun and others in 1998 and was one of the earliest convolutional neural networks. Its architecture is extremely simple but very efficient.\n","\n","There are three Convolutional Layers based on 5x5 filters and followed by average pooling with 2×2 patches. We use the ReLU function for activation as it leads to faster training. Then we add Dropout Layer with a factor of 0.2 to overcome overfitting. It means that 20% of the input will be randomly nullified to prevent strong dependencies between layers. We end up with Flattening and two Dense Layers. In the last Dense Layer, we have to assign the number of neurons equal to the number of classes, and the Softmax activation function to get probabilities between 0 and 1. The resulting number of weights in this network is 70,415."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_PtVQjUSXNyY"},"outputs":[],"source":["# Building the model\n","model = Sequential([\n","    Rescaling(1, input_shape=(32, 32, 1)),\n","    Conv2D(filters=6, kernel_size=(5, 5), activation='relu'),\n","    AveragePooling2D(pool_size=(2, 2)),\n","    Conv2D(filters=16, kernel_size=(5, 5), activation='relu'),\n","    AveragePooling2D(pool_size=(2, 2)),\n","    Conv2D(filters=120, kernel_size=(5, 5), activation='relu'),\n","    Dropout(0.2),\n","    Flatten(),\n","    Dense(units=120, activation='relu'),\n","    Dense(units=43, activation='softmax')\n","])\n","\n","# Compilation of the model\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Model architecture\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"orrFP7MwTxqV"},"source":["### 6. Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QbrDLC_fl0vM"},"outputs":[],"source":["history = model.fit(X_train, y_train, epochs=50,\n","                    validation_data=(X_test, y_test))"]},{"cell_type":"markdown","metadata":{"id":"5QXyFNhBmHug"},"source":["### 7. Evaluate training results\n","After 50 epochs we received an accuracy of about 99%, which is quite good. Thus we stop here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjnrhRNasGKy"},"outputs":[],"source":["val_loss, val_acc = model.evaluate(X_test, y_test, verbose=2)\n","print('\\nValifdation accuracy:', val_acc)\n","print('\\nValidation loss:', val_loss)"]},{"cell_type":"markdown","metadata":{"id":"DpGjsUOgnffC"},"source":["\n","Let's create plots of loss and accuracy on the training and validation sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hzMbItpQAEJj"},"outputs":[],"source":["plt.figure(0)\n","plt.plot(history.history['accuracy'], label='accuracy')\n","plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.ylim([0.8, 1])\n","plt.legend(loc='lower right')\n","\n","plt.figure(1)\n","plt.plot(history.history['loss'], label='loss')\n","plt.plot(history.history['val_loss'], label = 'val_loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.ylim([0, 0.2])\n","plt.legend(loc='lower right')"]},{"cell_type":"markdown","metadata":{"id":"gCxOPapepGb0"},"source":["As we see from the plots, train and validation accuracy go close, validation loss doesn't go up. So, the model looks fine, and we do not have much overfitting here."]},{"cell_type":"markdown","metadata":{"id":"5bcssiY_ws4W"},"source":["### 8. Prediction for sampless\n","Let's take a look at some samples and find the wrong classified pictures. We label the images with *prediction* and *ground truth* classes. If prediction equals ground truth, we assign a green color to the label, otherwise we make it red."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESSPq1D7Zvvs"},"outputs":[],"source":["preds = model.predict(X_test)\n","\n","plt.figure(figsize=(12, 12))\n","start_index = random.randint(0, 7800)\n","for i in range(25):\n","    plt.subplot(5, 5, i+1)\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    \n","    pred = np.argmax(preds[start_index+i])\n","    gt = np.argmax(y_test[start_index+i])\n","    \n","    col = 'g'\n","    if pred != gt:\n","        col = 'r'\n","    \n","    plt.xlabel('i={}, pred={}, gt={}'.format(start_index+i, pred, gt), color=col)\n","    plt.imshow(X_test[start_index+i], cmap='gray')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"UiQx6FAI1cGw"},"source":["For image number 5955 we can see that the \"Speed limit (50km/h)\" sign was misclassified as \"Speed limit (80km/h)\". Obviously, the text on the sign here is very hard to recognize."]},{"cell_type":"markdown","metadata":{"id":"1bG7IVNW8Mht"},"source":["### 9. Save the model\n","In the end, we save the model to a separate folder on Google Drive. It will be used for further predictions in the application for traffic signs recognition."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qr8WBFP7bMtO"},"outputs":[],"source":["model.save('/content/gdrive/My Drive/keras_model/')"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1mHleRqYFkTCP5NkI8ypyNCeUkNjLzbHs","timestamp":1666259975401}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}